{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "action_object_location_extraction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4jrT97KEc6u"
      },
      "source": [
        "###Checkpoints\n",
        "* Modelling - Done\n",
        "* config file and .py files for test and train - Done\n",
        "* Multi GPU training - Done\n",
        "* CPU inferencing which outputs F1 score - Done\n",
        "* Logging of training - Done\n",
        "* Documentation of project - PPT Done, Report Done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKDm7tCIUCr5"
      },
      "source": [
        "# RUNNING CODE FROM .PY AND CONFIG FILES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbQ05vs8Q4Bd"
      },
      "source": [
        "!pip install transformers --quiet"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsauMBq9RI6H",
        "outputId": "2b86d7be-4a88-4b18-9404-3b9f029c6769"
      },
      "source": [
        "!python3 saarthi_train.py --config external.json"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  grpc://10.104.183.170:8470\n",
            "2021-11-16 02:21:30.956192: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Using 8 TPUs\n",
            "Epoch 1/5\n",
            "23/23 [==============================] - 176s 4s/step - loss: 4.9733 - action_loss: 1.6652 - object_loss: 2.1854 - location_loss: 1.1227 - action_sparse_categorical_accuracy: 0.2672 - action_Top_3: 0.6429 - object_sparse_categorical_accuracy: 0.3370 - object_Top_3: 0.5389 - location_sparse_categorical_accuracy: 0.5316 - location_Top_3: 0.9043 - val_loss: 3.0032 - val_action_loss: 1.1267 - val_object_loss: 1.1651 - val_location_loss: 0.7113 - val_action_sparse_categorical_accuracy: 0.5654 - val_action_Top_3: 0.9320 - val_object_sparse_categorical_accuracy: 0.7300 - val_object_Top_3: 0.7906 - val_location_sparse_categorical_accuracy: 0.7768 - val_location_Top_3: 0.9644\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 5s 196ms/step - loss: 2.0479 - action_loss: 0.6863 - object_loss: 0.8563 - location_loss: 0.5052 - action_sparse_categorical_accuracy: 0.8459 - action_Top_3: 0.9739 - object_sparse_categorical_accuracy: 0.7733 - object_Top_3: 0.8866 - location_sparse_categorical_accuracy: 0.8464 - location_Top_3: 0.9854 - val_loss: 0.7204 - val_action_loss: 0.1515 - val_object_loss: 0.3072 - val_location_loss: 0.2616 - val_action_sparse_categorical_accuracy: 0.9945 - val_action_Top_3: 1.0000 - val_object_sparse_categorical_accuracy: 0.9416 - val_object_Top_3: 0.9775 - val_location_sparse_categorical_accuracy: 0.9885 - val_location_Top_3: 1.0000\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 4s 195ms/step - loss: 0.6165 - action_loss: 0.1416 - object_loss: 0.3182 - location_loss: 0.1567 - action_sparse_categorical_accuracy: 0.9920 - action_Top_3: 1.0000 - object_sparse_categorical_accuracy: 0.9490 - object_Top_3: 0.9813 - location_sparse_categorical_accuracy: 0.9926 - location_Top_3: 0.9999 - val_loss: 0.1770 - val_action_loss: 0.0326 - val_object_loss: 0.1119 - val_location_loss: 0.0326 - val_action_sparse_categorical_accuracy: 1.0000 - val_action_Top_3: 1.0000 - val_object_sparse_categorical_accuracy: 0.9872 - val_object_Top_3: 1.0000 - val_location_sparse_categorical_accuracy: 1.0000 - val_location_Top_3: 1.0000\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 5s 216ms/step - loss: 0.2265 - action_loss: 0.0488 - object_loss: 0.1375 - location_loss: 0.0402 - action_sparse_categorical_accuracy: 1.0000 - action_Top_3: 1.0000 - object_sparse_categorical_accuracy: 0.9858 - object_Top_3: 0.9991 - location_sparse_categorical_accuracy: 1.0000 - location_Top_3: 1.0000 - val_loss: 0.0662 - val_action_loss: 0.0136 - val_object_loss: 0.0395 - val_location_loss: 0.0131 - val_action_sparse_categorical_accuracy: 1.0000 - val_action_Top_3: 1.0000 - val_object_sparse_categorical_accuracy: 1.0000 - val_object_Top_3: 1.0000 - val_location_sparse_categorical_accuracy: 1.0000 - val_location_Top_3: 1.0000\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 4s 191ms/step - loss: 0.1092 - action_loss: 0.0269 - object_loss: 0.0605 - location_loss: 0.0217 - action_sparse_categorical_accuracy: 1.0000 - action_Top_3: 1.0000 - object_sparse_categorical_accuracy: 1.0000 - object_Top_3: 1.0000 - location_sparse_categorical_accuracy: 1.0000 - location_Top_3: 1.0000 - val_loss: 0.0302 - val_action_loss: 0.0085 - val_object_loss: 0.0133 - val_location_loss: 0.0084 - val_action_sparse_categorical_accuracy: 1.0000 - val_action_Top_3: 1.0000 - val_object_sparse_categorical_accuracy: 1.0000 - val_object_Top_3: 1.0000 - val_location_sparse_categorical_accuracy: 1.0000 - val_location_Top_3: 1.0000\n",
            "2021-11-16 02:25:51.753740: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154414080 exceeds 10% of free system memory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciOEu_80SvAY",
        "outputId": "7b4e7ce7-58ac-4935-ae76-c60e696c66e3"
      },
      "source": [
        "!python3 saarthi_test.py --config 'external.json'  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  grpc://10.104.183.170:8470\n",
            "2021-11-16 02:26:39.362645: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Using 8 TPUs\n",
            "F1 score for action--> 1.0\n",
            "F1 score for object--> 1.0\n",
            "F1 score for location--> 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl3C-HAeUNnS"
      },
      "source": [
        "# RUNNING IN COLAB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiqGmYeCNdgf"
      },
      "source": [
        "!pip install transformers --quiet\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import TFRobertaModel\n",
        "from keras.callbacks import CSVLogger\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import f1_score\n",
        "import warnings\n",
        "import logging, sys\n",
        "import os\n",
        "from datetime import datetime\n",
        "logging.disable(sys.maxsize)\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLvMkEFFqEOb",
        "outputId": "8643cbe6-c355-465f-fcc8-83d462fe4222"
      },
      "source": [
        "# Detect hardware, return appropriate distribution strategy, if tpus are available tpus are used\n",
        "# Else if gpus are available gpus are used. If neither are available computation is done with CPUs\n",
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    # Distribution strategy if tpus are available and is to be used\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "    print('Using {} TPUs'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "elif tf.config.list_physical_devices('GPU'):\n",
        "    # Distribution strategy in case of multiple GPUs\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "    print('Using {} GPUs'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "else:\n",
        "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "    print('No GPU nor TPU. Running on CPU')\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  grpc://10.104.183.170:8470\n",
            "Using 8 TPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKMxUe90AF_I"
      },
      "source": [
        "BATCH_SIZE = 512\n",
        "MAX_LEN = 13\n",
        "EPOCHS = 6\n",
        "NUM_ACTION = 6\n",
        "NUM_OBJECT = 14\n",
        "NUM_LOCATION = 4\n",
        "FOLDER_PATH = '/content/drive/MyDrive/Saarthi/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hovL3VEl-6M7"
      },
      "source": [
        "# TRAINING (IGNORE IF NOT NEEDED)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al4jkebeqCU7"
      },
      "source": [
        "train_df = pd.read_csv(FOLDER_PATH+'train_data.csv')\n",
        "val_df = pd.read_csv(FOLDER_PATH+'valid_data.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7DSTAF0O3md"
      },
      "source": [
        "action_enc = LabelEncoder()\n",
        "action_train = action_enc.fit_transform(train_df['action'])\n",
        "action_val = action_enc.transform(val_df['action'])\n",
        "\n",
        "object_enc = LabelEncoder()\n",
        "object_train = object_enc.fit_transform(train_df['object'])\n",
        "object_val = object_enc.transform(val_df['object'])\n",
        "\n",
        "location_enc = LabelEncoder()\n",
        "location_train = location_enc.fit_transform(train_df['location'])\n",
        "location_val = location_enc.transform(val_df['location'])\n",
        "\n",
        "texts = train_df['transcription'].values\n",
        "texts = list(texts)\n",
        "val_texts = val_df['transcription'].values\n",
        "val_texts = list(val_texts)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "train_data = tokenizer(texts, max_length=MAX_LEN, padding='max_length', truncation=True, return_tensors='tf')\n",
        "val_data = tokenizer(val_texts, max_length=MAX_LEN, padding='max_length', truncation=True, return_tensors='tf')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y_UJfG5PEm1"
      },
      "source": [
        "y_train = {'action': action_train, 'object':object_train, 'location': location_train}\n",
        "y_val = {'action': action_val, 'object':object_val, 'location': location_val}\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_data), y_train)).batch(BATCH_SIZE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((dict(val_data), y_val)).batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swfDznpzPEkV",
        "outputId": "8de4aefc-f037-4b94-b712-93f78ba3480e"
      },
      "source": [
        "%%time\n",
        "def build_model():\n",
        "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32, name='input_ids')\n",
        "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32, name='attention_mask')\n",
        "    bert_model = TFRobertaModel.from_pretrained(\"roberta-base\")\n",
        "    x = bert_model(ids,attention_mask=att)\n",
        "    x1 = tf.keras.layers.Flatten()(x[1])\n",
        "    x1 = tf.keras.layers.Dense(NUM_ACTION, name='action')(x1)\n",
        "\n",
        "    x2 = tf.keras.layers.Flatten()(x[1])\n",
        "    x2 = tf.keras.layers.Dense(NUM_OBJECT, name='object')(x2)\n",
        "\n",
        "    x3 = tf.keras.layers.Flatten()(x[1])\n",
        "    x3 = tf.keras.layers.Dense(NUM_LOCATION, name='location')(x3)\n",
        "    model = tf.keras.models.Model(inputs=[ids, att], outputs=[x1,x2,x3])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5, clipnorm=1.),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[tf.metrics.SparseCategoricalAccuracy(),tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3, name='Top_3')],\n",
        "        )\n",
        "    return model\n",
        "\n",
        "with strategy.scope():\n",
        "    model = build_model()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 16.2 s, sys: 6.69 s, total: 22.9 s\n",
            "Wall time: 49.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew9-sHFmhWAp",
        "outputId": "e7ca515a-b861-4259-d38f-9f3a7124aa5c"
      },
      "source": [
        "csv_logger = CSVLogger(FOLDER_PATH+'log.csv', append=True, separator=';')\n",
        "history=model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS, verbose=1, callbacks=[csv_logger])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "23/23 [==============================] - 176s 3s/step - loss: 5.0922 - action_loss: 1.6812 - object_loss: 2.2678 - location_loss: 1.1431 - action_sparse_categorical_accuracy: 0.2510 - action_Top_3: 0.6084 - object_sparse_categorical_accuracy: 0.2913 - object_Top_3: 0.5109 - location_sparse_categorical_accuracy: 0.5003 - location_Top_3: 0.8146 - val_loss: 3.0055 - val_action_loss: 1.0627 - val_object_loss: 1.2642 - val_location_loss: 0.6786 - val_action_sparse_categorical_accuracy: 0.7017 - val_action_Top_3: 0.9644 - val_object_sparse_categorical_accuracy: 0.7341 - val_object_Top_3: 0.7591 - val_location_sparse_categorical_accuracy: 0.7623 - val_location_Top_3: 0.9195\n",
            "Epoch 2/6\n",
            "23/23 [==============================] - 5s 197ms/step - loss: 2.1041 - action_loss: 0.7100 - object_loss: 0.8999 - location_loss: 0.4942 - action_sparse_categorical_accuracy: 0.8533 - action_Top_3: 0.9819 - object_sparse_categorical_accuracy: 0.7816 - object_Top_3: 0.8810 - location_sparse_categorical_accuracy: 0.8349 - location_Top_3: 0.9775 - val_loss: 0.7317 - val_action_loss: 0.1505 - val_object_loss: 0.3285 - val_location_loss: 0.2526 - val_action_sparse_categorical_accuracy: 0.9962 - val_action_Top_3: 1.0000 - val_object_sparse_categorical_accuracy: 0.9416 - val_object_Top_3: 0.9804 - val_location_sparse_categorical_accuracy: 0.9917 - val_location_Top_3: 1.0000\n",
            "Epoch 3/6\n",
            "23/23 [==============================] - 5s 201ms/step - loss: 0.6067 - action_loss: 0.1457 - object_loss: 0.3088 - location_loss: 0.1522 - action_sparse_categorical_accuracy: 0.9963 - action_Top_3: 1.0000 - object_sparse_categorical_accuracy: 0.9602 - object_Top_3: 0.9909 - location_sparse_categorical_accuracy: 0.9938 - location_Top_3: 1.0000 - val_loss: 0.1593 - val_action_loss: 0.0331 - val_object_loss: 0.0971 - val_location_loss: 0.0291 - val_action_sparse_categorical_accuracy: 1.0000 - val_action_Top_3: 1.0000 - val_object_sparse_categorical_accuracy: 1.0000 - val_object_Top_3: 1.0000 - val_location_sparse_categorical_accuracy: 1.0000 - val_location_Top_3: 1.0000\n",
            "Epoch 4/6\n",
            "23/23 [==============================] - 5s 199ms/step - loss: 0.2057 - action_loss: 0.0509 - object_loss: 0.1148 - location_loss: 0.0400 - action_sparse_categorical_accuracy: 0.9998 - action_Top_3: 1.0000 - object_sparse_categorical_accuracy: 0.9961 - object_Top_3: 1.0000 - location_sparse_categorical_accuracy: 1.0000 - location_Top_3: 1.0000 - val_loss: 0.0559 - val_action_loss: 0.0155 - val_object_loss: 0.0272 - val_location_loss: 0.0132 - val_action_sparse_categorical_accuracy: 1.0000 - val_action_Top_3: 1.0000 - val_object_sparse_categorical_accuracy: 1.0000 - val_object_Top_3: 1.0000 - val_location_sparse_categorical_accuracy: 1.0000 - val_location_Top_3: 1.0000\n",
            "Epoch 5/6\n",
            "23/23 [==============================] - 5s 199ms/step - loss: 0.0988 - action_loss: 0.0284 - object_loss: 0.0489 - location_loss: 0.0215 - action_sparse_categorical_accuracy: 1.0000 - action_Top_3: 1.0000 - object_sparse_categorical_accuracy: 0.9999 - object_Top_3: 1.0000 - location_sparse_categorical_accuracy: 1.0000 - location_Top_3: 1.0000 - val_loss: 0.0295 - val_action_loss: 0.0088 - val_object_loss: 0.0122 - val_location_loss: 0.0084 - val_action_sparse_categorical_accuracy: 1.0000 - val_action_Top_3: 1.0000 - val_object_sparse_categorical_accuracy: 1.0000 - val_object_Top_3: 1.0000 - val_location_sparse_categorical_accuracy: 1.0000 - val_location_Top_3: 1.0000\n",
            "Epoch 6/6\n",
            "23/23 [==============================] - 5s 200ms/step - loss: 0.0627 - action_loss: 0.0189 - object_loss: 0.0291 - location_loss: 0.0146 - action_sparse_categorical_accuracy: 0.9999 - action_Top_3: 1.0000 - object_sparse_categorical_accuracy: 1.0000 - object_Top_3: 1.0000 - location_sparse_categorical_accuracy: 1.0000 - location_Top_3: 1.0000 - val_loss: 0.0204 - val_action_loss: 0.0064 - val_object_loss: 0.0080 - val_location_loss: 0.0060 - val_action_sparse_categorical_accuracy: 1.0000 - val_action_Top_3: 1.0000 - val_object_sparse_categorical_accuracy: 1.0000 - val_object_Top_3: 1.0000 - val_location_sparse_categorical_accuracy: 1.0000 - val_location_Top_3: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M0qkxdr8hmN"
      },
      "source": [
        "model.save_weights(FOLDER_PATH+'model.h5')\n",
        "np.save(FOLDER_PATH+'action_encoder.npy', action_enc.classes_)\n",
        "np.save(FOLDER_PATH+'object_encoder.npy', object_enc.classes_)\n",
        "np.save(FOLDER_PATH+'location_encoder.npy', location_enc.classes_)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmpTBK1Mu66H"
      },
      "source": [
        "# PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AIpdhk9ahwA",
        "outputId": "74c89b16-aec3-4297-b3a3-33efc63dd37e"
      },
      "source": [
        "#folder containing model and the encoders\n",
        "FOLDER_PATH = '/content/drive/MyDrive/Saarthi/'\n",
        "#path to test dataset\n",
        "TEST_PATH = FOLDER_PATH+'valid_data.csv'\n",
        "\n",
        "\n",
        "test_df = pd.read_csv(TEST_PATH)\n",
        "\n",
        "action_enc = LabelEncoder()\n",
        "action_enc.classes_ = np.load(FOLDER_PATH+'action_encoder.npy', allow_pickle=True)\n",
        "action_test = action_enc.transform(test_df['action'])\n",
        "\n",
        "object_enc = LabelEncoder()\n",
        "object_enc.classes_ = np.load(FOLDER_PATH+'object_encoder.npy', allow_pickle=True)\n",
        "object_test = object_enc.transform(test_df['object'])\n",
        "\n",
        "location_enc = LabelEncoder()\n",
        "location_enc.classes_ = np.load(FOLDER_PATH+'location_encoder.npy', allow_pickle=True)\n",
        "location_test = location_enc.transform(test_df['location'])\n",
        "\n",
        "test_texts = test_df['transcription'].values\n",
        "test_texts = list(test_texts)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "MAX_LEN = 13\n",
        "test_data = tokenizer(test_texts, max_length=MAX_LEN, padding='max_length', truncation=True, return_tensors='tf')\n",
        "y_test = {'action': action_test, 'object':object_test, 'location': location_test}\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_data), y_test)).batch(BATCH_SIZE)\n",
        "\n",
        "def build_model():\n",
        "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32, name='input_ids')\n",
        "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32, name='attention_mask')\n",
        "    bert_model = TFRobertaModel.from_pretrained(\"roberta-base\")\n",
        "    x = bert_model(ids,attention_mask=att)\n",
        "    x1 = tf.keras.layers.Flatten()(x[1])\n",
        "    x1 = tf.keras.layers.Dense(NUM_ACTION, name='action')(x1)\n",
        "\n",
        "    x2 = tf.keras.layers.Flatten()(x[1])\n",
        "    x2 = tf.keras.layers.Dense(NUM_OBJECT, name='object')(x2)\n",
        "\n",
        "    x3 = tf.keras.layers.Flatten()(x[1])\n",
        "    x3 = tf.keras.layers.Dense(NUM_LOCATION, name='location')(x3)\n",
        "    model = tf.keras.models.Model(inputs=[ids, att], outputs=[x1,x2,x3])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5, clipnorm=1.),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[tf.metrics.SparseCategoricalAccuracy(),tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3, name='Top_3')],\n",
        "        )\n",
        "    return model\n",
        "\n",
        "with strategy.scope():\n",
        "    model = build_model()\n",
        "\n",
        "model.load_weights(FOLDER_PATH+'model.h5')\n",
        "ans = model.predict(test_dataset)\n",
        "\n",
        "action_preds = action_enc.inverse_transform(np.argmax(ans[0],axis=1))\n",
        "object_preds = object_enc.inverse_transform(np.argmax(ans[1],axis=1))\n",
        "location_preds = location_enc.inverse_transform(np.argmax(ans[2],axis=1))\n",
        "\n",
        "pred_df = pd.DataFrame({'input':test_df['transcription'],'action':test_df['action'],'object':test_df['object'],'location':test_df['location'],\n",
        "                        'action_preds':action_preds, 'object_preds':object_preds, 'location_preds':location_preds})\n",
        "\n",
        "# micro f1 score\n",
        "action_f1 = f1_score(pred_df['action_preds'],pred_df['action'], average='micro')\n",
        "object_f1 = f1_score(pred_df['object_preds'],pred_df['object'], average='micro')\n",
        "location_f1 = f1_score(pred_df['location_preds'],pred_df['location'], average='micro')\n",
        "print('F1 score for action-->',action_f1)\n",
        "print('F1 score for object-->',object_f1)\n",
        "print('F1 score for location-->',location_f1)\n",
        "pred_df.to_csv(FOLDER_PATH+'predictions.csv',index=False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score for action--> 1.0\n",
            "F1 score for object--> 1.0\n",
            "F1 score for location--> 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvC88KRREKro",
        "outputId": "77e80a85-b907-4021-e06c-9c3e47782a6e"
      },
      "source": [
        "print(pred_df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      input           action  ... object_preds location_preds\n",
            "0        Turn on the lights         activate  ...       lights           none\n",
            "1       Turn off the lights       deactivate  ...       lights           none\n",
            "2           Change language  change language  ...         none           none\n",
            "3           Pause the music       deactivate  ...        music           none\n",
            "4                    Resume         activate  ...        music           none\n",
            "...                     ...              ...  ...          ...            ...\n",
            "3113              Lights on         activate  ...       lights           none\n",
            "3114  Switch off the lights       deactivate  ...       lights           none\n",
            "3115    Turn the lights off       deactivate  ...       lights           none\n",
            "3116             Lights off       deactivate  ...       lights           none\n",
            "3117              Volume up         increase  ...       volume           none\n",
            "\n",
            "[3118 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOZLD1pwYGfd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}